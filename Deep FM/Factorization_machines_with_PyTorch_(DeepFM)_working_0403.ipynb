{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B5CiikKdHcQ"
      },
      "source": [
        "# Deep Fatorization Machines with PyTorch\n",
        "\n",
        "\n",
        "* Referneces :\n",
        "    - boostcamp ai tech, special mission (Recsys #4)\n",
        "    - DeepFM: A Factorization-Machine based Neural Network for CTR Prediction (https://arxiv.org/pdf/1703.04247.pdf)  \n",
        "    - Wide & Deep Learning for Recommender Systems (https://arxiv.org/pdf/1606.07792.pdf)\n",
        "    - Factorization Machines (https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694074)\n",
        "    - https://d2l.ai/chapter_recommender-systems/deepfm.html\n",
        "    - dataset : movielens modified w/o rating info."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rSLmkhCdHcR"
      },
      "source": [
        "# Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-HAIZoIdHcS"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgCzGVEpdHcT"
      },
      "source": [
        "# Data preprocessing\n",
        "0. Dataset 다운로드  \n",
        "<br/>\n",
        "1. Rating df 생성  \n",
        "rating 데이터(train_ratings.csv)를 불러와 [user, item, rating]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n",
        "<br/>\n",
        "2. Genre df 생성   \n",
        "genre 정보가 담긴 데이터(genres.tsv)를 불러와 genre이름을 id로 변경하고, [item, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.    \n",
        "<br/>\n",
        "3. Negative instances 생성   \n",
        "rating 데이터는 implicit feedback data(rating :0/1)로, positive instances로 구성되어 있습니다. 따라서 rating이 없는 item중 negative instances를 뽑아서 데이터에 추가하게 됩니다.   \n",
        "<br/>\n",
        "4. Join dfs   \n",
        "rating df와 genre df를 join하여 [user, item, rating, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n",
        "<br/>\n",
        "5. zero-based index로 mapping   \n",
        "Embedding을 위해서 user,item,genre를 zero-based index로 mapping합니다.\n",
        "    - user : 0-31359\n",
        "    - item : 0-6806\n",
        "    - genre : 0-17  \n",
        "<br/>\n",
        "6. feature matrix X, label tensor y 생성   \n",
        "[user, item, genre] 3개의 field로 구성된 feature matrix를 생성합니다.   \n",
        "<br/>\n",
        "7. data loader 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glQ_fDdvkbzk"
      },
      "source": [
        "## 데이터 다운로드\n",
        "이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요. \n",
        "- 데이터 URL은 변경될 수 있습니다.\n",
        "- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuYBEIhYdHcU",
        "outputId": "b5579ed8-6a0b-48e0-ebc2-fe4b71b1cc25"
      },
      "outputs": [],
      "source": [
        "# 1. Rating df 생성\n",
        "rating_data = \"./data/train/train_ratings.csv\"\n",
        "\n",
        "raw_rating_df = pd.read_csv(rating_data)\n",
        "raw_rating_df\n",
        "raw_rating_df['rating'] = 1.0 # implicit feedback\n",
        "raw_rating_df.drop(['time'],axis=1,inplace=True)\n",
        "print(\"Raw rating df\")\n",
        "print(raw_rating_df)\n",
        "\n",
        "users = set(raw_rating_df.loc[:, 'user'])\n",
        "items = set(raw_rating_df.loc[:, 'item'])\n",
        "\n",
        "#2. Genre df 생성\n",
        "genre_data = \"./data/train/genres.tsv\"\n",
        "\n",
        "raw_genre_df = pd.read_csv(genre_data, sep='\\t')\n",
        "raw_genre_df = raw_genre_df.drop_duplicates(subset=['item']) #item별 하나의 장르만 남도록 drop\n",
        "# print(raw_genre_df)\n",
        "\n",
        "genre_dict = {genre:i for i, genre in enumerate(set(raw_genre_df['genre']))}\n",
        "raw_genre_df['genre']  = raw_genre_df['genre'].map(lambda x : genre_dict[x]) #genre id로 변경\n",
        "print(\"Raw genre df - changed to id\")\n",
        "print(raw_genre_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKJ2oJURdHcV",
        "outputId": "0fe39bc3-70de-482f-bdbe-d738cb2d7381"
      },
      "outputs": [],
      "source": [
        "# 3. Negative instance 생성\n",
        "print(\"Create Nagetive instances\")\n",
        "num_negative = 50\n",
        "user_group_dfs = list(raw_rating_df.groupby('user')['item'])\n",
        "first_row = True\n",
        "user_neg_dfs = pd.DataFrame()\n",
        "\n",
        "for u, u_items in tqdm(user_group_dfs):\n",
        "    u_items = set(u_items)\n",
        "    i_user_neg_item = np.random.choice(list(items - u_items), num_negative, replace=False)\n",
        "    \n",
        "    i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'rating': [0]*num_negative})\n",
        "    if first_row == True:\n",
        "        user_neg_dfs = i_user_neg_df\n",
        "        first_row = False\n",
        "    else:\n",
        "        user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n",
        "\n",
        "raw_rating_df = pd.concat([raw_rating_df, user_neg_dfs], axis = 0, sort=False)\n",
        "\n",
        "# 4. Join dfs\n",
        "joined_rating_df = pd.merge(raw_rating_df, raw_genre_df, left_on='item', right_on='item', how='inner')\n",
        "# print(\"Joined rating df\")\n",
        "# print(joined_rating_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. user, item을 zero-based index로 mapping\n",
        "users = list(set(joined_rating_df.loc[:,'user']))\n",
        "users.sort()\n",
        "items =  list(set((joined_rating_df.loc[:, 'item'])))\n",
        "items.sort()\n",
        "genres =  list(set((joined_rating_df.loc[:, 'genre'])))\n",
        "genres.sort()\n",
        "\n",
        "if len(users)-1 != max(users):\n",
        "    users_dict = {users[i]: i for i in range(len(users))}\n",
        "    joined_rating_df['user']  = joined_rating_df['user'].map(lambda x : users_dict[x])\n",
        "    users = list(set(joined_rating_df.loc[:,'user']))\n",
        "    \n",
        "if len(items)-1 != max(items):\n",
        "    items_dict = {items[i]: i for i in range(len(items))}\n",
        "    joined_rating_df['item']  = joined_rating_df['item'].map(lambda x : items_dict[x])\n",
        "    items =  list(set((joined_rating_df.loc[:, 'item'])))\n",
        "\n",
        "joined_rating_df = joined_rating_df.sort_values(by=['user'])\n",
        "joined_rating_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "data = joined_rating_df\n",
        "# print(\"Data\")\n",
        "# print(data)\n",
        "\n",
        "n_data = len(data)\n",
        "n_user = len(users)\n",
        "n_item = len(items)\n",
        "n_genre = len(genres)\n",
        "\n",
        "print(\"# of data : {}\\n# of users : {}\\n# of items : {}\\n# of genres : {}\".format(n_data, n_user, n_item, n_genre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#6. feature matrix X, label tensor y 생성\n",
        "user_col = torch.tensor(data.loc[:,'user'])\n",
        "item_col = torch.tensor(data.loc[:,'item'])\n",
        "genre_col = torch.tensor(data.loc[:,'genre'])\n",
        "\n",
        "offsets = [0, n_user, n_user+n_item]\n",
        "for col, offset in zip([user_col, item_col, genre_col], offsets):\n",
        "    col += offset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3N75T9GdHcV"
      },
      "outputs": [],
      "source": [
        "X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1), genre_col.unsqueeze(1)], dim=1)\n",
        "y = torch.tensor(list(data.loc[:,'rating']))\n",
        "\n",
        "#7. data loader 생성\n",
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, input_tensor, target_tensor):\n",
        "        self.input_tensor = input_tensor.long()\n",
        "        self.target_tensor = target_tensor.long()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_tensor[index], self.target_tensor[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_tensor.size(0)\n",
        "\n",
        "\n",
        "dataset = RatingDataset(X, y)\n",
        "train_ratio = 0.9\n",
        "\n",
        "train_size = int(train_ratio * len(data))\n",
        "test_size = len(data) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgDhK2Q6dHcW"
      },
      "source": [
        "   # Model architecture (DeepFM)\n",
        "   DeepFM 모델은 1) FM component와  2) Deep component가 병렬적으로 결합되어 있습니다. 구조는 다음과 같습니다.\n",
        "<img src='https://drive.google.com/uc?id=1vwcxUJQTIsg5QH9CuH5PcUEfExhToUHR'>  \n",
        "각 구조는 다음과 같습니다.  \n",
        "   **1. FM component**  \n",
        "       FM component는 우리가 아는 2-way Factorization machines(degree=2)입니다. FM은 variables 간의 interaction을 다음과 같이 모델링 합니다.   \n",
        "     **<center> equation (1) </center>**\n",
        "   $$\\hat{y}(x):=w_0 + \\sum_{i=1}^{n}w_ix_i + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j$$   \n",
        "   이때, 세번째 interaction term을 전개하여 다음과 같이 쓸 수 있습니다.(논문 참고)  \n",
        "   구현 코드는 전개된 식을 바탕으로 합니다.   \n",
        "     **<center> equation (2)> </center>**\n",
        "   $$\\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j = \\frac{1}{2}\\sum_{f=1}^{k}((\\sum_{i=1}^{n}v_{i,f}x_i)^2-\\sum_{i=1}^{n}v_{i,f}^2x_i^2)$$   \n",
        "           \n",
        "   **2. Deep component**  \n",
        "       Deep component는 MLP Layers로 구성되어 있습니다.   \n",
        "       구현 코드는 Input dimension이 30-20-10인 3 layer MLP 구조입니다.\n",
        "  \n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxcLoGw2dHcW"
      },
      "source": [
        "# DeepFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SytZGp2_dHcW"
      },
      "outputs": [],
      "source": [
        "class DeepFM(nn.Module):\n",
        "    def __init__(self, input_dims, embedding_dim, mlp_dims, drop_rate=0.1):\n",
        "        super(DeepFM, self).__init__()\n",
        "        total_input_dim = int(sum(input_dims)) # n_user + n_movie + n_genre\n",
        "\n",
        "        # Fm component의 constant bias term과 1차 bias term\n",
        "        self.bias = nn.Parameter(torch.zeros((1,)))\n",
        "        self.fc = nn.Embedding(total_input_dim, 1)\n",
        "        \n",
        "        self.embedding = nn.Embedding(total_input_dim, embedding_dim) \n",
        "        self.embedding_dim = len(input_dims) * embedding_dim\n",
        "\n",
        "        mlp_layers = []\n",
        "        for i, dim in enumerate(mlp_dims):\n",
        "            if i==0:\n",
        "                mlp_layers.append(nn.Linear(self.embedding_dim, dim))\n",
        "            else:\n",
        "                mlp_layers.append(nn.Linear(mlp_dims[i-1], dim)) #TODO 1 : linear layer를 넣어주세요.\n",
        "            mlp_layers.append(nn.ReLU(True))\n",
        "            mlp_layers.append(nn.Dropout(drop_rate))\n",
        "        mlp_layers.append(nn.Linear(mlp_dims[-1], 1))\n",
        "        self.mlp_layers = nn.Sequential(*mlp_layers)\n",
        "\n",
        "    def fm(self, x):\n",
        "        # x : (batch_size, total_num_input)\n",
        "        embed_x = self.embedding(x)\n",
        "\n",
        "        fm_y = self.bias + torch.sum(self.fc(x), dim=1)\n",
        "        square_of_sum = torch.sum(embed_x, dim=1) ** 2         #TODO 2 : torch.sum을 이용하여 square_of_sum을 작성해주세요(hint : equation (2))\n",
        "        sum_of_square = torch.sum(embed_x ** 2, dim=1)         #TODO 3 : torch.sum을 이용하여 sum_of_square을 작성해주세요(hint : equation (2))\n",
        "        fm_y += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n",
        "        return fm_y\n",
        "    \n",
        "    def mlp(self, x):\n",
        "        embed_x = self.embedding(x)\n",
        "        # print(embed_x.shape)\n",
        "        # print(x.shape)\n",
        "        \n",
        "        inputs = embed_x.view(-1, self.embedding_dim)\n",
        "        mlp_y = self.mlp_layers(inputs)\n",
        "        return mlp_y\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed_x = self.embedding(x)\n",
        "        #fm component\n",
        "        fm_y = self.fm(x).squeeze(1)\n",
        "        \n",
        "        #deep component\n",
        "        mlp_y = self.mlp(x).squeeze(1)\n",
        "        \n",
        "        y = torch.sigmoid(fm_y + mlp_y)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR-AgXXpdHcX"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aEtDR5EdHcX",
        "outputId": "ab74a388-e2e4-48a7-91da-364a638c0d31"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "input_dims = [n_user, n_item, n_genre]\n",
        "# print(input_dims)\n",
        "embedding_dim = 10\n",
        "model = DeepFM(input_dims, embedding_dim, mlp_dims=[30, 20, 10]).to(device)\n",
        "bce_loss = nn.BCELoss() # Binary Cross Entropy loss\n",
        "lr, num_epochs = 0.001, 100\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for e in tqdm(range(num_epochs)) :\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = bce_loss(output, y.float())\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "torch.save(model, \"dfm.pt\")\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Top-N List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 1. Generate dataset (ux(i,g))\n",
        "- 2. predict ratings for all joint (u, i)\n",
        "- 3. rating index (unseen) [:10]\n",
        "- 4. make submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X , y 생성하기\n",
        "# X : [user, {item, genre}], for all users, u and all {item, genre}, i_g \n",
        "##### y : [0] * len(user) * len{item, genre}  --> 형태만 맞추기. 사용되지 않음. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Users list 생성하기 \n",
        "rating_df = pd.read_csv(\"data/train/train_ratings.csv\")\n",
        "rating_df.drop(['time'],axis=1,inplace=True)\n",
        "users = list(set(rating_df.loc[:,'user'])) # list(rating_df['user'].unique())  # NAME_list\n",
        "# n_users = 31360, users.min = 11,  users.max = 138493\n",
        "\n",
        "# 2. Items, genres list 생성하기 \n",
        "genre_df = pd.read_csv(\"data/train/genres.tsv\", sep='\\t')\n",
        "genre_df = genre_df.drop_duplicates(subset=['item'])\n",
        "items = list(set(genre_df.loc[:,'item'])) # list(genre_df['item'].unique())\n",
        "genres = list(set(genre_df.loc[:,'genre']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. user, item, genre를 zero-based index로 mapping\n",
        "users_dict = {users[i]: i for i in range(len(users))}\n",
        "rating_df['user']  = rating_df['user'].map(lambda x : users_dict[x])\n",
        "users_zero = list(set(rating_df.loc[:,'user']))\n",
        "\n",
        "items_dict = {items[i] : i for i in range(len(items))}\n",
        "genre_df['item']  = genre_df['item'].map(lambda x : items_dict[x])\n",
        "items_zero =  list(set((genre_df.loc[:, 'item'])))\n",
        "\n",
        "genre_dict = {genre:i for i, genre in enumerate(set(genre_df['genre']))}\n",
        "genre_df['genre']  = genre_df['genre'].map(lambda x : genre_dict[x]) #genre id로 변경\n",
        "genres_zero = list(genre_df['genre'] ) # list(set(genre_df.loc[:,'genre'])) # list(genre_df['genre'])\n",
        "# genres = list(genre_df['genre'])\n",
        "\n",
        "n_item = len(items)\n",
        "n_user = len(users)\n",
        "n_genre = len(genres)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(len(users_zero), len(items_zero), len(genres_zero))\n",
        "# print(min(users_zero), min(items_zero), min(genres_zero))\n",
        "# print(max(users_zero), max(items_zero), max(genres_zero))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('data/train/train_ratings.csv')\n",
        "ratings['rating'] = 1.0\n",
        "\n",
        "ratings_df = ratings[['user', 'item', 'rating']]\n",
        "# column = 'title'로 title 컬럼으로 pivot 수행\n",
        "ratings_matrix = ratings_df.pivot_table('rating', index='user', columns='item')\n",
        "\n",
        "# # NaN 값을 모두 0으로 변환\n",
        "ratings_matrix = ratings_matrix.fillna(0)\n",
        "ratings_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recomm_movie_by_userid(pred_df, userId, unseen_list, top_n=10):\n",
        "    # 예측 평점 DataFrame에서 사용자id index와 unseen_list로 들어온 영화명 컬럼을 추출하여\n",
        "    # 가장 예측 평점이 높은 순으로 정렬함.\n",
        "    res_dict = {pred_df[i]: i for i in range(len(pred_df))}\n",
        "    pred = pred_df.sort()\n",
        "    res_movie_ids = [ items[i] for i in result.sort().indices.tolist()]\n",
        "    recomm_ids = list(set(res_movie_ids) & set(unseen_list))\n",
        "\n",
        "    return res_movie_ids[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_unseen_movies(ratings_matrix, userId):\n",
        "    # userId로 입력받은 사용자의 모든 영화정보 추출하여 Series로 반환함. \n",
        "    # 반환된 user_rating 은 영화명(title)을 index로 가지는 Series 객체임. \n",
        "    \n",
        "    user_rating = ratings_matrix.loc[userId,:]\n",
        "    # user_rating이 0보다 크면 기존에 관람한 영화임. 대상 index를 추출하여 list 객체로 만듬\n",
        "\n",
        "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
        "    # 모든 영화명을 list 객체로 만듬. \n",
        "    movies_list = ratings_matrix.columns.tolist()\n",
        "    \n",
        "    # list comprehension으로 already_seen에 해당하는 movie는 movies_list에서 제외함. \n",
        "    unseen_list = [ movie for movie in movies_list if movie not in already_seen]\n",
        "    \n",
        "    return unseen_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#7. data loader 생성\n",
        "\n",
        "# offsets = [0, n_user, n_user+n_item]\n",
        "# for col, offset in zip([user_col, item_col, genre_col], offsets):\n",
        "#     col += offset\n",
        "\n",
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, input_tensor, target_tensor):\n",
        "        self.input_tensor = input_tensor.long()\n",
        "        self.target_tensor = target_tensor.long()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_tensor[index], self.target_tensor[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target_tensor.size(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "items_sr = pd.Series(data = items_zero)\n",
        "genres_sr = pd.Series(data = genres_zero)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mp_items = []\n",
        "users_ = []\n",
        "itr = 0\n",
        "\n",
        "item_col = torch.tensor(items_sr)\n",
        "genre_col = torch.tensor(genres_sr)\n",
        "\n",
        "for u in tqdm(users_zero):\n",
        "    user_col = torch.tensor(pd.Series([u]* n_item))\n",
        "\n",
        "    # offsets = [0, n_user, n_user+n_item]\n",
        "    # for col, offset in zip([user_col, item_col, genre_col], offsets):\n",
        "    #     col += offset\n",
        "\n",
        "    X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1), genre_col.unsqueeze(1)], dim=1)\n",
        "    y = torch.tensor(list([0]*len(items)))\n",
        "   \n",
        "    cf_test_dataset = RatingDataset(X, y)\n",
        "    cf_test_loader = DataLoader(cf_test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "    result = torch.tensor([]).to(device)\n",
        "    for x, y in cf_test_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        model.eval()\n",
        "        output = model(x)\n",
        "        result = torch.cat((result, output), 0)\n",
        "    \n",
        "    # 사용자가 관람하지 않는 영화명 추출   \n",
        "    unseen_list = get_unseen_movies(ratings_matrix, users[u])   \n",
        "\n",
        "    # 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천 \n",
        "    recomm_movies = recomm_movie_by_userid(result, users[u], unseen_list, top_n=10)\n",
        "    mp_items= mp_items + recomm_movies\n",
        "    users_ = users_ + [users[u]]*10 # [u, u, u, u, u, u, u, u, u, u]\n",
        "\n",
        "test_df = pd.DataFrame(zip(users_,mp_items), columns=['user','item'])\n",
        "test_df.to_csv(\"submission_DeepFM.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = test_df.sort_values(by=[\"user\"], ascending=[True])\n",
        "test_df.to_csv(\"submission_DeepFM_sorted.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Mission3 _Factorization machines with PyTorch (DeepFM)-정답.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

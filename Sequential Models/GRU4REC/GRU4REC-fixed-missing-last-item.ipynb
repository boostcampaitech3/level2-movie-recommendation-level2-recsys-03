{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a29b5e",
   "metadata": {},
   "source": [
    "Reference : RecBole (https://recbole.io/) \n",
    "+ sequential-model-fixed-missing-last-item.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7316f",
   "metadata": {
    "papermill": {
     "duration": 0.072866,
     "end_time": "2022-03-20T02:26:17.434227",
     "exception": false,
     "start_time": "2022-03-20T02:26:17.361361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Create dataset and train model with Recbole\n",
    "\n",
    "For anyone need instruction document, please check this link: https://recbole.io/docs/user_guide/usage/use_modules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "861094fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T02:26:17.582780Z",
     "iopub.status.busy": "2022-03-20T02:26:17.581666Z",
     "iopub.status.idle": "2022-03-20T02:26:20.280026Z",
     "shell.execute_reply": "2022-03-20T02:26:20.280632Z",
     "shell.execute_reply.started": "2022-03-19T09:10:04.781373Z"
    },
    "papermill": {
     "duration": 2.773509,
     "end_time": "2022-03-20T02:26:20.280830",
     "exception": false,
     "start_time": "2022-03-20T02:26:17.507321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c211ad36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T02:26:20.438539Z",
     "iopub.status.busy": "2022-03-20T02:26:20.437533Z",
     "iopub.status.idle": "2022-03-20T02:26:21.300145Z",
     "shell.execute_reply": "2022-03-20T02:26:21.007505Z",
     "shell.execute_reply.started": "2022-03-19T09:10:07.54699Z"
    },
    "papermill": {
     "duration": 0.946555,
     "end_time": "2022-03-20T02:26:21.300340",
     "exception": false,
     "start_time": "2022-03-20T02:26:20.353785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13 Apr 09:22    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/RecBole/srcs/dataset/ml_bc\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [30,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/RecBole/srcs/dataset/ml_bc\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [30,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/RecBole/srcs/dataset/ml_bc\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [30,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/RecBole/srcs/dataset/ml_bc\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [30,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/RecBole/srcs/dataset/ml_bc\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [30,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_dict = {\n",
    "    'data_path': '/opt/ml/RecBole/srcs/dataset',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'user_inter_num_interval': \"[30,inf)\",\n",
    "    'item_inter_num_interval': \"[40,inf)\",\n",
    "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
    "    'neg_sampling': None,\n",
    "    'epochs': 100,\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [10, 0, 0]},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'}\n",
    "}\n",
    "\n",
    "config = Config(model='GRU4Rec', dataset='ml_bc', config_dict=parameter_dict)\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "548e2d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T02:26:21.722138Z",
     "iopub.status.busy": "2022-03-20T02:26:21.720998Z",
     "iopub.status.idle": "2022-03-20T02:27:55.478058Z",
     "shell.execute_reply": "2022-03-20T02:27:55.460191Z",
     "shell.execute_reply.started": "2022-03-19T09:10:08.225437Z"
    },
    "papermill": {
     "duration": 93.969404,
     "end_time": "2022-03-20T02:27:55.478219",
     "exception": false,
     "start_time": "2022-03-20T02:26:21.508815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13 Apr 09:22    INFO  ml_bc\n",
      "The number of users: 31357\n",
      "Average actions of users: 164.3724327082536\n",
      "The number of items: 6799\n",
      "Average actions of items: 758.1732862606649\n",
      "The number of inters: 5154062\n",
      "The sparsity of the dataset: 97.58247991265024%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "ml_bc\n",
      "The number of users: 31357\n",
      "Average actions of users: 164.3724327082536\n",
      "The number of items: 6799\n",
      "Average actions of items: 758.1732862606649\n",
      "The number of inters: 5154062\n",
      "The sparsity of the dataset: 97.58247991265024%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "ml_bc\n",
      "The number of users: 31357\n",
      "Average actions of users: 164.3724327082536\n",
      "The number of items: 6799\n",
      "Average actions of items: 758.1732862606649\n",
      "The number of inters: 5154062\n",
      "The sparsity of the dataset: 97.58247991265024%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "ml_bc\n",
      "The number of users: 31357\n",
      "Average actions of users: 164.3724327082536\n",
      "The number of items: 6799\n",
      "Average actions of items: 758.1732862606649\n",
      "The number of inters: 5154062\n",
      "The sparsity of the dataset: 97.58247991265024%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "ml_bc\n",
      "The number of users: 31357\n",
      "Average actions of users: 164.3724327082536\n",
      "The number of items: 6799\n",
      "Average actions of items: 758.1732862606649\n",
      "The number of inters: 5154062\n",
      "The sparsity of the dataset: 97.58247991265024%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c74775e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T02:27:55.906921Z",
     "iopub.status.busy": "2022-03-20T02:27:55.906288Z",
     "iopub.status.idle": "2022-03-20T02:28:37.269123Z",
     "shell.execute_reply": "2022-03-20T02:28:37.252513Z",
     "shell.execute_reply.started": "2022-03-19T09:11:36.745731Z"
    },
    "papermill": {
     "duration": 41.580573,
     "end_time": "2022-03-20T02:28:37.269274",
     "exception": false,
     "start_time": "2022-03-20T02:27:55.688701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13 Apr 09:23    INFO  [Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "13 Apr 09:23    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [10, 0, 0]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9645ae09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T02:28:37.715732Z",
     "iopub.status.busy": "2022-03-20T02:28:37.714892Z",
     "iopub.status.idle": "2022-03-20T02:50:21.046599Z",
     "shell.execute_reply": "2022-03-20T02:50:21.045317Z",
     "shell.execute_reply.started": "2022-03-19T09:12:13.351077Z"
    },
    "papermill": {
     "duration": 1303.559679,
     "end_time": "2022-03-20T02:50:21.046804",
     "exception": false,
     "start_time": "2022-03-20T02:28:37.487125",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13 Apr 09:23    INFO  GRU4Rec(\n",
      "  (item_embedding): Embedding(6799, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 517120\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(6799, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 517120\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(6799, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 517120\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(6799, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 517120\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(6799, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 517120\n",
      "13 Apr 09:24    INFO  epoch 0 training [time: 42.25s, train loss: 17814.1576]\n",
      "epoch 0 training [time: 42.25s, train loss: 17814.1576]\n",
      "epoch 0 training [time: 42.25s, train loss: 17814.1576]\n",
      "epoch 0 training [time: 42.25s, train loss: 17814.1576]\n",
      "epoch 0 training [time: 42.25s, train loss: 17814.1576]\n",
      "13 Apr 09:24    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:25    INFO  epoch 1 training [time: 42.18s, train loss: 16450.5641]\n",
      "epoch 1 training [time: 42.18s, train loss: 16450.5641]\n",
      "epoch 1 training [time: 42.18s, train loss: 16450.5641]\n",
      "epoch 1 training [time: 42.18s, train loss: 16450.5641]\n",
      "epoch 1 training [time: 42.18s, train loss: 16450.5641]\n",
      "13 Apr 09:25    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:25    INFO  epoch 2 training [time: 42.25s, train loss: 16000.1570]\n",
      "epoch 2 training [time: 42.25s, train loss: 16000.1570]\n",
      "epoch 2 training [time: 42.25s, train loss: 16000.1570]\n",
      "epoch 2 training [time: 42.25s, train loss: 16000.1570]\n",
      "epoch 2 training [time: 42.25s, train loss: 16000.1570]\n",
      "13 Apr 09:25    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:26    INFO  epoch 3 training [time: 42.23s, train loss: 15793.1091]\n",
      "epoch 3 training [time: 42.23s, train loss: 15793.1091]\n",
      "epoch 3 training [time: 42.23s, train loss: 15793.1091]\n",
      "epoch 3 training [time: 42.23s, train loss: 15793.1091]\n",
      "epoch 3 training [time: 42.23s, train loss: 15793.1091]\n",
      "13 Apr 09:26    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:27    INFO  epoch 4 training [time: 42.61s, train loss: 15654.9565]\n",
      "epoch 4 training [time: 42.61s, train loss: 15654.9565]\n",
      "epoch 4 training [time: 42.61s, train loss: 15654.9565]\n",
      "epoch 4 training [time: 42.61s, train loss: 15654.9565]\n",
      "epoch 4 training [time: 42.61s, train loss: 15654.9565]\n",
      "13 Apr 09:27    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:28    INFO  epoch 5 training [time: 43.76s, train loss: 15551.8331]\n",
      "epoch 5 training [time: 43.76s, train loss: 15551.8331]\n",
      "epoch 5 training [time: 43.76s, train loss: 15551.8331]\n",
      "epoch 5 training [time: 43.76s, train loss: 15551.8331]\n",
      "epoch 5 training [time: 43.76s, train loss: 15551.8331]\n",
      "13 Apr 09:28    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:28    INFO  epoch 6 training [time: 42.10s, train loss: 15474.9042]\n",
      "epoch 6 training [time: 42.10s, train loss: 15474.9042]\n",
      "epoch 6 training [time: 42.10s, train loss: 15474.9042]\n",
      "epoch 6 training [time: 42.10s, train loss: 15474.9042]\n",
      "epoch 6 training [time: 42.10s, train loss: 15474.9042]\n",
      "13 Apr 09:28    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:29    INFO  epoch 7 training [time: 42.29s, train loss: 15413.8613]\n",
      "epoch 7 training [time: 42.29s, train loss: 15413.8613]\n",
      "epoch 7 training [time: 42.29s, train loss: 15413.8613]\n",
      "epoch 7 training [time: 42.29s, train loss: 15413.8613]\n",
      "epoch 7 training [time: 42.29s, train loss: 15413.8613]\n",
      "13 Apr 09:29    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:30    INFO  epoch 8 training [time: 41.98s, train loss: 15363.4675]\n",
      "epoch 8 training [time: 41.98s, train loss: 15363.4675]\n",
      "epoch 8 training [time: 41.98s, train loss: 15363.4675]\n",
      "epoch 8 training [time: 41.98s, train loss: 15363.4675]\n",
      "epoch 8 training [time: 41.98s, train loss: 15363.4675]\n",
      "13 Apr 09:30    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:30    INFO  epoch 9 training [time: 42.11s, train loss: 15321.4940]\n",
      "epoch 9 training [time: 42.11s, train loss: 15321.4940]\n",
      "epoch 9 training [time: 42.11s, train loss: 15321.4940]\n",
      "epoch 9 training [time: 42.11s, train loss: 15321.4940]\n",
      "epoch 9 training [time: 42.11s, train loss: 15321.4940]\n",
      "13 Apr 09:30    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:31    INFO  epoch 10 training [time: 42.37s, train loss: 15284.9561]\n",
      "epoch 10 training [time: 42.37s, train loss: 15284.9561]\n",
      "epoch 10 training [time: 42.37s, train loss: 15284.9561]\n",
      "epoch 10 training [time: 42.37s, train loss: 15284.9561]\n",
      "epoch 10 training [time: 42.37s, train loss: 15284.9561]\n",
      "13 Apr 09:31    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:32    INFO  epoch 11 training [time: 42.29s, train loss: 15252.1548]\n",
      "epoch 11 training [time: 42.29s, train loss: 15252.1548]\n",
      "epoch 11 training [time: 42.29s, train loss: 15252.1548]\n",
      "epoch 11 training [time: 42.29s, train loss: 15252.1548]\n",
      "epoch 11 training [time: 42.29s, train loss: 15252.1548]\n",
      "13 Apr 09:32    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:33    INFO  epoch 12 training [time: 42.10s, train loss: 15223.2952]\n",
      "epoch 12 training [time: 42.10s, train loss: 15223.2952]\n",
      "epoch 12 training [time: 42.10s, train loss: 15223.2952]\n",
      "epoch 12 training [time: 42.10s, train loss: 15223.2952]\n",
      "epoch 12 training [time: 42.10s, train loss: 15223.2952]\n",
      "13 Apr 09:33    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:33    INFO  epoch 13 training [time: 42.29s, train loss: 15196.9533]\n",
      "epoch 13 training [time: 42.29s, train loss: 15196.9533]\n",
      "epoch 13 training [time: 42.29s, train loss: 15196.9533]\n",
      "epoch 13 training [time: 42.29s, train loss: 15196.9533]\n",
      "epoch 13 training [time: 42.29s, train loss: 15196.9533]\n",
      "13 Apr 09:33    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:34    INFO  epoch 14 training [time: 42.09s, train loss: 15174.3749]\n",
      "epoch 14 training [time: 42.09s, train loss: 15174.3749]\n",
      "epoch 14 training [time: 42.09s, train loss: 15174.3749]\n",
      "epoch 14 training [time: 42.09s, train loss: 15174.3749]\n",
      "epoch 14 training [time: 42.09s, train loss: 15174.3749]\n",
      "13 Apr 09:34    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:35    INFO  epoch 15 training [time: 42.24s, train loss: 15154.7794]\n",
      "epoch 15 training [time: 42.24s, train loss: 15154.7794]\n",
      "epoch 15 training [time: 42.24s, train loss: 15154.7794]\n",
      "epoch 15 training [time: 42.24s, train loss: 15154.7794]\n",
      "epoch 15 training [time: 42.24s, train loss: 15154.7794]\n",
      "13 Apr 09:35    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:35    INFO  epoch 16 training [time: 42.09s, train loss: 15136.7884]\n",
      "epoch 16 training [time: 42.09s, train loss: 15136.7884]\n",
      "epoch 16 training [time: 42.09s, train loss: 15136.7884]\n",
      "epoch 16 training [time: 42.09s, train loss: 15136.7884]\n",
      "epoch 16 training [time: 42.09s, train loss: 15136.7884]\n",
      "13 Apr 09:35    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:36    INFO  epoch 17 training [time: 42.07s, train loss: 15120.7396]\n",
      "epoch 17 training [time: 42.07s, train loss: 15120.7396]\n",
      "epoch 17 training [time: 42.07s, train loss: 15120.7396]\n",
      "epoch 17 training [time: 42.07s, train loss: 15120.7396]\n",
      "epoch 17 training [time: 42.07s, train loss: 15120.7396]\n",
      "13 Apr 09:36    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:37    INFO  epoch 18 training [time: 42.20s, train loss: 15106.3920]\n",
      "epoch 18 training [time: 42.20s, train loss: 15106.3920]\n",
      "epoch 18 training [time: 42.20s, train loss: 15106.3920]\n",
      "epoch 18 training [time: 42.20s, train loss: 15106.3920]\n",
      "epoch 18 training [time: 42.20s, train loss: 15106.3920]\n",
      "13 Apr 09:37    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:37    INFO  epoch 19 training [time: 42.15s, train loss: 15094.0425]\n",
      "epoch 19 training [time: 42.15s, train loss: 15094.0425]\n",
      "epoch 19 training [time: 42.15s, train loss: 15094.0425]\n",
      "epoch 19 training [time: 42.15s, train loss: 15094.0425]\n",
      "epoch 19 training [time: 42.15s, train loss: 15094.0425]\n",
      "13 Apr 09:37    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:38    INFO  epoch 20 training [time: 42.46s, train loss: 15082.5385]\n",
      "epoch 20 training [time: 42.46s, train loss: 15082.5385]\n",
      "epoch 20 training [time: 42.46s, train loss: 15082.5385]\n",
      "epoch 20 training [time: 42.46s, train loss: 15082.5385]\n",
      "epoch 20 training [time: 42.46s, train loss: 15082.5385]\n",
      "13 Apr 09:38    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:39    INFO  epoch 21 training [time: 42.32s, train loss: 15071.3806]\n",
      "epoch 21 training [time: 42.32s, train loss: 15071.3806]\n",
      "epoch 21 training [time: 42.32s, train loss: 15071.3806]\n",
      "epoch 21 training [time: 42.32s, train loss: 15071.3806]\n",
      "epoch 21 training [time: 42.32s, train loss: 15071.3806]\n",
      "13 Apr 09:39    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:40    INFO  epoch 22 training [time: 42.38s, train loss: 15062.3166]\n",
      "epoch 22 training [time: 42.38s, train loss: 15062.3166]\n",
      "epoch 22 training [time: 42.38s, train loss: 15062.3166]\n",
      "epoch 22 training [time: 42.38s, train loss: 15062.3166]\n",
      "epoch 22 training [time: 42.38s, train loss: 15062.3166]\n",
      "13 Apr 09:40    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:40    INFO  epoch 23 training [time: 42.59s, train loss: 15052.0790]\n",
      "epoch 23 training [time: 42.59s, train loss: 15052.0790]\n",
      "epoch 23 training [time: 42.59s, train loss: 15052.0790]\n",
      "epoch 23 training [time: 42.59s, train loss: 15052.0790]\n",
      "epoch 23 training [time: 42.59s, train loss: 15052.0790]\n",
      "13 Apr 09:40    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:41    INFO  epoch 24 training [time: 42.35s, train loss: 15043.2758]\n",
      "epoch 24 training [time: 42.35s, train loss: 15043.2758]\n",
      "epoch 24 training [time: 42.35s, train loss: 15043.2758]\n",
      "epoch 24 training [time: 42.35s, train loss: 15043.2758]\n",
      "epoch 24 training [time: 42.35s, train loss: 15043.2758]\n",
      "13 Apr 09:41    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:42    INFO  epoch 25 training [time: 42.29s, train loss: 15035.0534]\n",
      "epoch 25 training [time: 42.29s, train loss: 15035.0534]\n",
      "epoch 25 training [time: 42.29s, train loss: 15035.0534]\n",
      "epoch 25 training [time: 42.29s, train loss: 15035.0534]\n",
      "epoch 25 training [time: 42.29s, train loss: 15035.0534]\n",
      "13 Apr 09:42    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:42    INFO  epoch 26 training [time: 42.21s, train loss: 15027.0560]\n",
      "epoch 26 training [time: 42.21s, train loss: 15027.0560]\n",
      "epoch 26 training [time: 42.21s, train loss: 15027.0560]\n",
      "epoch 26 training [time: 42.21s, train loss: 15027.0560]\n",
      "epoch 26 training [time: 42.21s, train loss: 15027.0560]\n",
      "13 Apr 09:42    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:43    INFO  epoch 27 training [time: 42.43s, train loss: 15019.7603]\n",
      "epoch 27 training [time: 42.43s, train loss: 15019.7603]\n",
      "epoch 27 training [time: 42.43s, train loss: 15019.7603]\n",
      "epoch 27 training [time: 42.43s, train loss: 15019.7603]\n",
      "epoch 27 training [time: 42.43s, train loss: 15019.7603]\n",
      "13 Apr 09:43    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:44    INFO  epoch 28 training [time: 42.43s, train loss: 15012.7551]\n",
      "epoch 28 training [time: 42.43s, train loss: 15012.7551]\n",
      "epoch 28 training [time: 42.43s, train loss: 15012.7551]\n",
      "epoch 28 training [time: 42.43s, train loss: 15012.7551]\n",
      "epoch 28 training [time: 42.43s, train loss: 15012.7551]\n",
      "13 Apr 09:44    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:45    INFO  epoch 29 training [time: 42.26s, train loss: 15006.1730]\n",
      "epoch 29 training [time: 42.26s, train loss: 15006.1730]\n",
      "epoch 29 training [time: 42.26s, train loss: 15006.1730]\n",
      "epoch 29 training [time: 42.26s, train loss: 15006.1730]\n",
      "epoch 29 training [time: 42.26s, train loss: 15006.1730]\n",
      "13 Apr 09:45    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:45    INFO  epoch 30 training [time: 42.15s, train loss: 15000.3446]\n",
      "epoch 30 training [time: 42.15s, train loss: 15000.3446]\n",
      "epoch 30 training [time: 42.15s, train loss: 15000.3446]\n",
      "epoch 30 training [time: 42.15s, train loss: 15000.3446]\n",
      "epoch 30 training [time: 42.15s, train loss: 15000.3446]\n",
      "13 Apr 09:45    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:46    INFO  epoch 31 training [time: 42.14s, train loss: 14993.0926]\n",
      "epoch 31 training [time: 42.14s, train loss: 14993.0926]\n",
      "epoch 31 training [time: 42.14s, train loss: 14993.0926]\n",
      "epoch 31 training [time: 42.14s, train loss: 14993.0926]\n",
      "epoch 31 training [time: 42.14s, train loss: 14993.0926]\n",
      "13 Apr 09:46    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:47    INFO  epoch 32 training [time: 42.17s, train loss: 14987.8786]\n",
      "epoch 32 training [time: 42.17s, train loss: 14987.8786]\n",
      "epoch 32 training [time: 42.17s, train loss: 14987.8786]\n",
      "epoch 32 training [time: 42.17s, train loss: 14987.8786]\n",
      "epoch 32 training [time: 42.17s, train loss: 14987.8786]\n",
      "13 Apr 09:47    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:47    INFO  epoch 33 training [time: 42.24s, train loss: 14982.8338]\n",
      "epoch 33 training [time: 42.24s, train loss: 14982.8338]\n",
      "epoch 33 training [time: 42.24s, train loss: 14982.8338]\n",
      "epoch 33 training [time: 42.24s, train loss: 14982.8338]\n",
      "epoch 33 training [time: 42.24s, train loss: 14982.8338]\n",
      "13 Apr 09:47    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:48    INFO  epoch 34 training [time: 42.21s, train loss: 14978.0267]\n",
      "epoch 34 training [time: 42.21s, train loss: 14978.0267]\n",
      "epoch 34 training [time: 42.21s, train loss: 14978.0267]\n",
      "epoch 34 training [time: 42.21s, train loss: 14978.0267]\n",
      "epoch 34 training [time: 42.21s, train loss: 14978.0267]\n",
      "13 Apr 09:48    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:49    INFO  epoch 35 training [time: 42.34s, train loss: 14973.2582]\n",
      "epoch 35 training [time: 42.34s, train loss: 14973.2582]\n",
      "epoch 35 training [time: 42.34s, train loss: 14973.2582]\n",
      "epoch 35 training [time: 42.34s, train loss: 14973.2582]\n",
      "epoch 35 training [time: 42.34s, train loss: 14973.2582]\n",
      "13 Apr 09:49    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:49    INFO  epoch 36 training [time: 42.33s, train loss: 14968.7800]\n",
      "epoch 36 training [time: 42.33s, train loss: 14968.7800]\n",
      "epoch 36 training [time: 42.33s, train loss: 14968.7800]\n",
      "epoch 36 training [time: 42.33s, train loss: 14968.7800]\n",
      "epoch 36 training [time: 42.33s, train loss: 14968.7800]\n",
      "13 Apr 09:49    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:50    INFO  epoch 37 training [time: 42.62s, train loss: 14964.0236]\n",
      "epoch 37 training [time: 42.62s, train loss: 14964.0236]\n",
      "epoch 37 training [time: 42.62s, train loss: 14964.0236]\n",
      "epoch 37 training [time: 42.62s, train loss: 14964.0236]\n",
      "epoch 37 training [time: 42.62s, train loss: 14964.0236]\n",
      "13 Apr 09:50    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:51    INFO  epoch 38 training [time: 42.22s, train loss: 14959.3542]\n",
      "epoch 38 training [time: 42.22s, train loss: 14959.3542]\n",
      "epoch 38 training [time: 42.22s, train loss: 14959.3542]\n",
      "epoch 38 training [time: 42.22s, train loss: 14959.3542]\n",
      "epoch 38 training [time: 42.22s, train loss: 14959.3542]\n",
      "13 Apr 09:51    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:52    INFO  epoch 39 training [time: 42.32s, train loss: 14956.9438]\n",
      "epoch 39 training [time: 42.32s, train loss: 14956.9438]\n",
      "epoch 39 training [time: 42.32s, train loss: 14956.9438]\n",
      "epoch 39 training [time: 42.32s, train loss: 14956.9438]\n",
      "epoch 39 training [time: 42.32s, train loss: 14956.9438]\n",
      "13 Apr 09:52    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:52    INFO  epoch 40 training [time: 42.24s, train loss: 14952.9937]\n",
      "epoch 40 training [time: 42.24s, train loss: 14952.9937]\n",
      "epoch 40 training [time: 42.24s, train loss: 14952.9937]\n",
      "epoch 40 training [time: 42.24s, train loss: 14952.9937]\n",
      "epoch 40 training [time: 42.24s, train loss: 14952.9937]\n",
      "13 Apr 09:52    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:53    INFO  epoch 41 training [time: 42.29s, train loss: 14949.1522]\n",
      "epoch 41 training [time: 42.29s, train loss: 14949.1522]\n",
      "epoch 41 training [time: 42.29s, train loss: 14949.1522]\n",
      "epoch 41 training [time: 42.29s, train loss: 14949.1522]\n",
      "epoch 41 training [time: 42.29s, train loss: 14949.1522]\n",
      "13 Apr 09:53    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:54    INFO  epoch 42 training [time: 42.22s, train loss: 14945.5663]\n",
      "epoch 42 training [time: 42.22s, train loss: 14945.5663]\n",
      "epoch 42 training [time: 42.22s, train loss: 14945.5663]\n",
      "epoch 42 training [time: 42.22s, train loss: 14945.5663]\n",
      "epoch 42 training [time: 42.22s, train loss: 14945.5663]\n",
      "13 Apr 09:54    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:54    INFO  epoch 43 training [time: 42.09s, train loss: 14941.5635]\n",
      "epoch 43 training [time: 42.09s, train loss: 14941.5635]\n",
      "epoch 43 training [time: 42.09s, train loss: 14941.5635]\n",
      "epoch 43 training [time: 42.09s, train loss: 14941.5635]\n",
      "epoch 43 training [time: 42.09s, train loss: 14941.5635]\n",
      "13 Apr 09:54    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:55    INFO  epoch 44 training [time: 42.09s, train loss: 14939.4047]\n",
      "epoch 44 training [time: 42.09s, train loss: 14939.4047]\n",
      "epoch 44 training [time: 42.09s, train loss: 14939.4047]\n",
      "epoch 44 training [time: 42.09s, train loss: 14939.4047]\n",
      "epoch 44 training [time: 42.09s, train loss: 14939.4047]\n",
      "13 Apr 09:55    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:56    INFO  epoch 45 training [time: 42.17s, train loss: 14935.8974]\n",
      "epoch 45 training [time: 42.17s, train loss: 14935.8974]\n",
      "epoch 45 training [time: 42.17s, train loss: 14935.8974]\n",
      "epoch 45 training [time: 42.17s, train loss: 14935.8974]\n",
      "epoch 45 training [time: 42.17s, train loss: 14935.8974]\n",
      "13 Apr 09:56    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:57    INFO  epoch 46 training [time: 42.32s, train loss: 14931.3595]\n",
      "epoch 46 training [time: 42.32s, train loss: 14931.3595]\n",
      "epoch 46 training [time: 42.32s, train loss: 14931.3595]\n",
      "epoch 46 training [time: 42.32s, train loss: 14931.3595]\n",
      "epoch 46 training [time: 42.32s, train loss: 14931.3595]\n",
      "13 Apr 09:57    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:57    INFO  epoch 47 training [time: 42.13s, train loss: 14929.6864]\n",
      "epoch 47 training [time: 42.13s, train loss: 14929.6864]\n",
      "epoch 47 training [time: 42.13s, train loss: 14929.6864]\n",
      "epoch 47 training [time: 42.13s, train loss: 14929.6864]\n",
      "epoch 47 training [time: 42.13s, train loss: 14929.6864]\n",
      "13 Apr 09:57    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:58    INFO  epoch 48 training [time: 41.97s, train loss: 14927.3775]\n",
      "epoch 48 training [time: 41.97s, train loss: 14927.3775]\n",
      "epoch 48 training [time: 41.97s, train loss: 14927.3775]\n",
      "epoch 48 training [time: 41.97s, train loss: 14927.3775]\n",
      "epoch 48 training [time: 41.97s, train loss: 14927.3775]\n",
      "13 Apr 09:58    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:59    INFO  epoch 49 training [time: 42.03s, train loss: 14924.1247]\n",
      "epoch 49 training [time: 42.03s, train loss: 14924.1247]\n",
      "epoch 49 training [time: 42.03s, train loss: 14924.1247]\n",
      "epoch 49 training [time: 42.03s, train loss: 14924.1247]\n",
      "epoch 49 training [time: 42.03s, train loss: 14924.1247]\n",
      "13 Apr 09:59    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 09:59    INFO  epoch 50 training [time: 42.10s, train loss: 14920.8408]\n",
      "epoch 50 training [time: 42.10s, train loss: 14920.8408]\n",
      "epoch 50 training [time: 42.10s, train loss: 14920.8408]\n",
      "epoch 50 training [time: 42.10s, train loss: 14920.8408]\n",
      "epoch 50 training [time: 42.10s, train loss: 14920.8408]\n",
      "13 Apr 09:59    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:00    INFO  epoch 51 training [time: 42.33s, train loss: 14919.4024]\n",
      "epoch 51 training [time: 42.33s, train loss: 14919.4024]\n",
      "epoch 51 training [time: 42.33s, train loss: 14919.4024]\n",
      "epoch 51 training [time: 42.33s, train loss: 14919.4024]\n",
      "epoch 51 training [time: 42.33s, train loss: 14919.4024]\n",
      "13 Apr 10:00    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:01    INFO  epoch 52 training [time: 42.08s, train loss: 14916.2946]\n",
      "epoch 52 training [time: 42.08s, train loss: 14916.2946]\n",
      "epoch 52 training [time: 42.08s, train loss: 14916.2946]\n",
      "epoch 52 training [time: 42.08s, train loss: 14916.2946]\n",
      "epoch 52 training [time: 42.08s, train loss: 14916.2946]\n",
      "13 Apr 10:01    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:01    INFO  epoch 53 training [time: 41.99s, train loss: 14914.2954]\n",
      "epoch 53 training [time: 41.99s, train loss: 14914.2954]\n",
      "epoch 53 training [time: 41.99s, train loss: 14914.2954]\n",
      "epoch 53 training [time: 41.99s, train loss: 14914.2954]\n",
      "epoch 53 training [time: 41.99s, train loss: 14914.2954]\n",
      "13 Apr 10:01    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:02    INFO  epoch 54 training [time: 41.85s, train loss: 14911.2469]\n",
      "epoch 54 training [time: 41.85s, train loss: 14911.2469]\n",
      "epoch 54 training [time: 41.85s, train loss: 14911.2469]\n",
      "epoch 54 training [time: 41.85s, train loss: 14911.2469]\n",
      "epoch 54 training [time: 41.85s, train loss: 14911.2469]\n",
      "13 Apr 10:02    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:03    INFO  epoch 55 training [time: 42.15s, train loss: 14908.9195]\n",
      "epoch 55 training [time: 42.15s, train loss: 14908.9195]\n",
      "epoch 55 training [time: 42.15s, train loss: 14908.9195]\n",
      "epoch 55 training [time: 42.15s, train loss: 14908.9195]\n",
      "epoch 55 training [time: 42.15s, train loss: 14908.9195]\n",
      "13 Apr 10:03    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:04    INFO  epoch 56 training [time: 42.09s, train loss: 14907.0663]\n",
      "epoch 56 training [time: 42.09s, train loss: 14907.0663]\n",
      "epoch 56 training [time: 42.09s, train loss: 14907.0663]\n",
      "epoch 56 training [time: 42.09s, train loss: 14907.0663]\n",
      "epoch 56 training [time: 42.09s, train loss: 14907.0663]\n",
      "13 Apr 10:04    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:04    INFO  epoch 57 training [time: 41.87s, train loss: 14903.8849]\n",
      "epoch 57 training [time: 41.87s, train loss: 14903.8849]\n",
      "epoch 57 training [time: 41.87s, train loss: 14903.8849]\n",
      "epoch 57 training [time: 41.87s, train loss: 14903.8849]\n",
      "epoch 57 training [time: 41.87s, train loss: 14903.8849]\n",
      "13 Apr 10:04    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:05    INFO  epoch 58 training [time: 42.56s, train loss: 14901.6766]\n",
      "epoch 58 training [time: 42.56s, train loss: 14901.6766]\n",
      "epoch 58 training [time: 42.56s, train loss: 14901.6766]\n",
      "epoch 58 training [time: 42.56s, train loss: 14901.6766]\n",
      "epoch 58 training [time: 42.56s, train loss: 14901.6766]\n",
      "13 Apr 10:05    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:06    INFO  epoch 59 training [time: 42.03s, train loss: 14900.6508]\n",
      "epoch 59 training [time: 42.03s, train loss: 14900.6508]\n",
      "epoch 59 training [time: 42.03s, train loss: 14900.6508]\n",
      "epoch 59 training [time: 42.03s, train loss: 14900.6508]\n",
      "epoch 59 training [time: 42.03s, train loss: 14900.6508]\n",
      "13 Apr 10:06    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:06    INFO  epoch 60 training [time: 42.00s, train loss: 14898.0265]\n",
      "epoch 60 training [time: 42.00s, train loss: 14898.0265]\n",
      "epoch 60 training [time: 42.00s, train loss: 14898.0265]\n",
      "epoch 60 training [time: 42.00s, train loss: 14898.0265]\n",
      "epoch 60 training [time: 42.00s, train loss: 14898.0265]\n",
      "13 Apr 10:06    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:07    INFO  epoch 61 training [time: 41.94s, train loss: 14895.8605]\n",
      "epoch 61 training [time: 41.94s, train loss: 14895.8605]\n",
      "epoch 61 training [time: 41.94s, train loss: 14895.8605]\n",
      "epoch 61 training [time: 41.94s, train loss: 14895.8605]\n",
      "epoch 61 training [time: 41.94s, train loss: 14895.8605]\n",
      "13 Apr 10:07    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:08    INFO  epoch 62 training [time: 42.46s, train loss: 14894.4303]\n",
      "epoch 62 training [time: 42.46s, train loss: 14894.4303]\n",
      "epoch 62 training [time: 42.46s, train loss: 14894.4303]\n",
      "epoch 62 training [time: 42.46s, train loss: 14894.4303]\n",
      "epoch 62 training [time: 42.46s, train loss: 14894.4303]\n",
      "13 Apr 10:08    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:08    INFO  epoch 63 training [time: 42.89s, train loss: 14892.7432]\n",
      "epoch 63 training [time: 42.89s, train loss: 14892.7432]\n",
      "epoch 63 training [time: 42.89s, train loss: 14892.7432]\n",
      "epoch 63 training [time: 42.89s, train loss: 14892.7432]\n",
      "epoch 63 training [time: 42.89s, train loss: 14892.7432]\n",
      "13 Apr 10:08    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:09    INFO  epoch 64 training [time: 42.25s, train loss: 14891.2908]\n",
      "epoch 64 training [time: 42.25s, train loss: 14891.2908]\n",
      "epoch 64 training [time: 42.25s, train loss: 14891.2908]\n",
      "epoch 64 training [time: 42.25s, train loss: 14891.2908]\n",
      "epoch 64 training [time: 42.25s, train loss: 14891.2908]\n",
      "13 Apr 10:09    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:10    INFO  epoch 65 training [time: 41.87s, train loss: 14888.0152]\n",
      "epoch 65 training [time: 41.87s, train loss: 14888.0152]\n",
      "epoch 65 training [time: 41.87s, train loss: 14888.0152]\n",
      "epoch 65 training [time: 41.87s, train loss: 14888.0152]\n",
      "epoch 65 training [time: 41.87s, train loss: 14888.0152]\n",
      "13 Apr 10:10    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:11    INFO  epoch 66 training [time: 41.78s, train loss: 14886.5335]\n",
      "epoch 66 training [time: 41.78s, train loss: 14886.5335]\n",
      "epoch 66 training [time: 41.78s, train loss: 14886.5335]\n",
      "epoch 66 training [time: 41.78s, train loss: 14886.5335]\n",
      "epoch 66 training [time: 41.78s, train loss: 14886.5335]\n",
      "13 Apr 10:11    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:11    INFO  epoch 67 training [time: 42.26s, train loss: 14885.2164]\n",
      "epoch 67 training [time: 42.26s, train loss: 14885.2164]\n",
      "epoch 67 training [time: 42.26s, train loss: 14885.2164]\n",
      "epoch 67 training [time: 42.26s, train loss: 14885.2164]\n",
      "epoch 67 training [time: 42.26s, train loss: 14885.2164]\n",
      "13 Apr 10:11    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:12    INFO  epoch 68 training [time: 42.70s, train loss: 14882.7934]\n",
      "epoch 68 training [time: 42.70s, train loss: 14882.7934]\n",
      "epoch 68 training [time: 42.70s, train loss: 14882.7934]\n",
      "epoch 68 training [time: 42.70s, train loss: 14882.7934]\n",
      "epoch 68 training [time: 42.70s, train loss: 14882.7934]\n",
      "13 Apr 10:12    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:13    INFO  epoch 69 training [time: 42.12s, train loss: 14881.0072]\n",
      "epoch 69 training [time: 42.12s, train loss: 14881.0072]\n",
      "epoch 69 training [time: 42.12s, train loss: 14881.0072]\n",
      "epoch 69 training [time: 42.12s, train loss: 14881.0072]\n",
      "epoch 69 training [time: 42.12s, train loss: 14881.0072]\n",
      "13 Apr 10:13    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:13    INFO  epoch 70 training [time: 42.19s, train loss: 14879.6043]\n",
      "epoch 70 training [time: 42.19s, train loss: 14879.6043]\n",
      "epoch 70 training [time: 42.19s, train loss: 14879.6043]\n",
      "epoch 70 training [time: 42.19s, train loss: 14879.6043]\n",
      "epoch 70 training [time: 42.19s, train loss: 14879.6043]\n",
      "13 Apr 10:13    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:14    INFO  epoch 71 training [time: 42.13s, train loss: 14877.4787]\n",
      "epoch 71 training [time: 42.13s, train loss: 14877.4787]\n",
      "epoch 71 training [time: 42.13s, train loss: 14877.4787]\n",
      "epoch 71 training [time: 42.13s, train loss: 14877.4787]\n",
      "epoch 71 training [time: 42.13s, train loss: 14877.4787]\n",
      "13 Apr 10:14    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:15    INFO  epoch 72 training [time: 41.91s, train loss: 14875.8848]\n",
      "epoch 72 training [time: 41.91s, train loss: 14875.8848]\n",
      "epoch 72 training [time: 41.91s, train loss: 14875.8848]\n",
      "epoch 72 training [time: 41.91s, train loss: 14875.8848]\n",
      "epoch 72 training [time: 41.91s, train loss: 14875.8848]\n",
      "13 Apr 10:15    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:16    INFO  epoch 73 training [time: 41.99s, train loss: 14874.7992]\n",
      "epoch 73 training [time: 41.99s, train loss: 14874.7992]\n",
      "epoch 73 training [time: 41.99s, train loss: 14874.7992]\n",
      "epoch 73 training [time: 41.99s, train loss: 14874.7992]\n",
      "epoch 73 training [time: 41.99s, train loss: 14874.7992]\n",
      "13 Apr 10:16    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:16    INFO  epoch 74 training [time: 42.17s, train loss: 14872.9330]\n",
      "epoch 74 training [time: 42.17s, train loss: 14872.9330]\n",
      "epoch 74 training [time: 42.17s, train loss: 14872.9330]\n",
      "epoch 74 training [time: 42.17s, train loss: 14872.9330]\n",
      "epoch 74 training [time: 42.17s, train loss: 14872.9330]\n",
      "13 Apr 10:16    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:17    INFO  epoch 75 training [time: 42.11s, train loss: 14871.8105]\n",
      "epoch 75 training [time: 42.11s, train loss: 14871.8105]\n",
      "epoch 75 training [time: 42.11s, train loss: 14871.8105]\n",
      "epoch 75 training [time: 42.11s, train loss: 14871.8105]\n",
      "epoch 75 training [time: 42.11s, train loss: 14871.8105]\n",
      "13 Apr 10:17    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:18    INFO  epoch 76 training [time: 42.25s, train loss: 14869.9586]\n",
      "epoch 76 training [time: 42.25s, train loss: 14869.9586]\n",
      "epoch 76 training [time: 42.25s, train loss: 14869.9586]\n",
      "epoch 76 training [time: 42.25s, train loss: 14869.9586]\n",
      "epoch 76 training [time: 42.25s, train loss: 14869.9586]\n",
      "13 Apr 10:18    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:18    INFO  epoch 77 training [time: 42.13s, train loss: 14868.6310]\n",
      "epoch 77 training [time: 42.13s, train loss: 14868.6310]\n",
      "epoch 77 training [time: 42.13s, train loss: 14868.6310]\n",
      "epoch 77 training [time: 42.13s, train loss: 14868.6310]\n",
      "epoch 77 training [time: 42.13s, train loss: 14868.6310]\n",
      "13 Apr 10:18    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:19    INFO  epoch 78 training [time: 42.10s, train loss: 14866.4921]\n",
      "epoch 78 training [time: 42.10s, train loss: 14866.4921]\n",
      "epoch 78 training [time: 42.10s, train loss: 14866.4921]\n",
      "epoch 78 training [time: 42.10s, train loss: 14866.4921]\n",
      "epoch 78 training [time: 42.10s, train loss: 14866.4921]\n",
      "13 Apr 10:19    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:20    INFO  epoch 79 training [time: 42.08s, train loss: 14865.0811]\n",
      "epoch 79 training [time: 42.08s, train loss: 14865.0811]\n",
      "epoch 79 training [time: 42.08s, train loss: 14865.0811]\n",
      "epoch 79 training [time: 42.08s, train loss: 14865.0811]\n",
      "epoch 79 training [time: 42.08s, train loss: 14865.0811]\n",
      "13 Apr 10:20    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:20    INFO  epoch 80 training [time: 42.05s, train loss: 14864.4164]\n",
      "epoch 80 training [time: 42.05s, train loss: 14864.4164]\n",
      "epoch 80 training [time: 42.05s, train loss: 14864.4164]\n",
      "epoch 80 training [time: 42.05s, train loss: 14864.4164]\n",
      "epoch 80 training [time: 42.05s, train loss: 14864.4164]\n",
      "13 Apr 10:20    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:21    INFO  epoch 81 training [time: 42.21s, train loss: 14862.9928]\n",
      "epoch 81 training [time: 42.21s, train loss: 14862.9928]\n",
      "epoch 81 training [time: 42.21s, train loss: 14862.9928]\n",
      "epoch 81 training [time: 42.21s, train loss: 14862.9928]\n",
      "epoch 81 training [time: 42.21s, train loss: 14862.9928]\n",
      "13 Apr 10:21    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:22    INFO  epoch 82 training [time: 42.05s, train loss: 14861.3386]\n",
      "epoch 82 training [time: 42.05s, train loss: 14861.3386]\n",
      "epoch 82 training [time: 42.05s, train loss: 14861.3386]\n",
      "epoch 82 training [time: 42.05s, train loss: 14861.3386]\n",
      "epoch 82 training [time: 42.05s, train loss: 14861.3386]\n",
      "13 Apr 10:22    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:23    INFO  epoch 83 training [time: 42.15s, train loss: 14859.9077]\n",
      "epoch 83 training [time: 42.15s, train loss: 14859.9077]\n",
      "epoch 83 training [time: 42.15s, train loss: 14859.9077]\n",
      "epoch 83 training [time: 42.15s, train loss: 14859.9077]\n",
      "epoch 83 training [time: 42.15s, train loss: 14859.9077]\n",
      "13 Apr 10:23    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:23    INFO  epoch 84 training [time: 42.09s, train loss: 14859.9805]\n",
      "epoch 84 training [time: 42.09s, train loss: 14859.9805]\n",
      "epoch 84 training [time: 42.09s, train loss: 14859.9805]\n",
      "epoch 84 training [time: 42.09s, train loss: 14859.9805]\n",
      "epoch 84 training [time: 42.09s, train loss: 14859.9805]\n",
      "13 Apr 10:23    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:24    INFO  epoch 85 training [time: 42.39s, train loss: 14858.0917]\n",
      "epoch 85 training [time: 42.39s, train loss: 14858.0917]\n",
      "epoch 85 training [time: 42.39s, train loss: 14858.0917]\n",
      "epoch 85 training [time: 42.39s, train loss: 14858.0917]\n",
      "epoch 85 training [time: 42.39s, train loss: 14858.0917]\n",
      "13 Apr 10:24    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:25    INFO  epoch 86 training [time: 42.38s, train loss: 14855.8474]\n",
      "epoch 86 training [time: 42.38s, train loss: 14855.8474]\n",
      "epoch 86 training [time: 42.38s, train loss: 14855.8474]\n",
      "epoch 86 training [time: 42.38s, train loss: 14855.8474]\n",
      "epoch 86 training [time: 42.38s, train loss: 14855.8474]\n",
      "13 Apr 10:25    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:25    INFO  epoch 87 training [time: 42.12s, train loss: 14855.1648]\n",
      "epoch 87 training [time: 42.12s, train loss: 14855.1648]\n",
      "epoch 87 training [time: 42.12s, train loss: 14855.1648]\n",
      "epoch 87 training [time: 42.12s, train loss: 14855.1648]\n",
      "epoch 87 training [time: 42.12s, train loss: 14855.1648]\n",
      "13 Apr 10:25    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:26    INFO  epoch 88 training [time: 42.06s, train loss: 14853.3885]\n",
      "epoch 88 training [time: 42.06s, train loss: 14853.3885]\n",
      "epoch 88 training [time: 42.06s, train loss: 14853.3885]\n",
      "epoch 88 training [time: 42.06s, train loss: 14853.3885]\n",
      "epoch 88 training [time: 42.06s, train loss: 14853.3885]\n",
      "13 Apr 10:26    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:27    INFO  epoch 89 training [time: 41.96s, train loss: 14852.9558]\n",
      "epoch 89 training [time: 41.96s, train loss: 14852.9558]\n",
      "epoch 89 training [time: 41.96s, train loss: 14852.9558]\n",
      "epoch 89 training [time: 41.96s, train loss: 14852.9558]\n",
      "epoch 89 training [time: 41.96s, train loss: 14852.9558]\n",
      "13 Apr 10:27    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:27    INFO  epoch 90 training [time: 42.37s, train loss: 14851.2096]\n",
      "epoch 90 training [time: 42.37s, train loss: 14851.2096]\n",
      "epoch 90 training [time: 42.37s, train loss: 14851.2096]\n",
      "epoch 90 training [time: 42.37s, train loss: 14851.2096]\n",
      "epoch 90 training [time: 42.37s, train loss: 14851.2096]\n",
      "13 Apr 10:27    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:28    INFO  epoch 91 training [time: 41.90s, train loss: 14850.6345]\n",
      "epoch 91 training [time: 41.90s, train loss: 14850.6345]\n",
      "epoch 91 training [time: 41.90s, train loss: 14850.6345]\n",
      "epoch 91 training [time: 41.90s, train loss: 14850.6345]\n",
      "epoch 91 training [time: 41.90s, train loss: 14850.6345]\n",
      "13 Apr 10:28    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:29    INFO  epoch 92 training [time: 41.94s, train loss: 14849.5448]\n",
      "epoch 92 training [time: 41.94s, train loss: 14849.5448]\n",
      "epoch 92 training [time: 41.94s, train loss: 14849.5448]\n",
      "epoch 92 training [time: 41.94s, train loss: 14849.5448]\n",
      "epoch 92 training [time: 41.94s, train loss: 14849.5448]\n",
      "13 Apr 10:29    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:30    INFO  epoch 93 training [time: 41.98s, train loss: 14848.8967]\n",
      "epoch 93 training [time: 41.98s, train loss: 14848.8967]\n",
      "epoch 93 training [time: 41.98s, train loss: 14848.8967]\n",
      "epoch 93 training [time: 41.98s, train loss: 14848.8967]\n",
      "epoch 93 training [time: 41.98s, train loss: 14848.8967]\n",
      "13 Apr 10:30    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:30    INFO  epoch 94 training [time: 42.50s, train loss: 14847.1928]\n",
      "epoch 94 training [time: 42.50s, train loss: 14847.1928]\n",
      "epoch 94 training [time: 42.50s, train loss: 14847.1928]\n",
      "epoch 94 training [time: 42.50s, train loss: 14847.1928]\n",
      "epoch 94 training [time: 42.50s, train loss: 14847.1928]\n",
      "13 Apr 10:30    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:31    INFO  epoch 95 training [time: 42.23s, train loss: 14845.3615]\n",
      "epoch 95 training [time: 42.23s, train loss: 14845.3615]\n",
      "epoch 95 training [time: 42.23s, train loss: 14845.3615]\n",
      "epoch 95 training [time: 42.23s, train loss: 14845.3615]\n",
      "epoch 95 training [time: 42.23s, train loss: 14845.3615]\n",
      "13 Apr 10:31    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:32    INFO  epoch 96 training [time: 42.50s, train loss: 14845.4485]\n",
      "epoch 96 training [time: 42.50s, train loss: 14845.4485]\n",
      "epoch 96 training [time: 42.50s, train loss: 14845.4485]\n",
      "epoch 96 training [time: 42.50s, train loss: 14845.4485]\n",
      "epoch 96 training [time: 42.50s, train loss: 14845.4485]\n",
      "13 Apr 10:32    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:32    INFO  epoch 97 training [time: 42.13s, train loss: 14843.6068]\n",
      "epoch 97 training [time: 42.13s, train loss: 14843.6068]\n",
      "epoch 97 training [time: 42.13s, train loss: 14843.6068]\n",
      "epoch 97 training [time: 42.13s, train loss: 14843.6068]\n",
      "epoch 97 training [time: 42.13s, train loss: 14843.6068]\n",
      "13 Apr 10:32    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:33    INFO  epoch 98 training [time: 42.09s, train loss: 14843.7893]\n",
      "epoch 98 training [time: 42.09s, train loss: 14843.7893]\n",
      "epoch 98 training [time: 42.09s, train loss: 14843.7893]\n",
      "epoch 98 training [time: 42.09s, train loss: 14843.7893]\n",
      "epoch 98 training [time: 42.09s, train loss: 14843.7893]\n",
      "13 Apr 10:33    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "13 Apr 10:34    INFO  epoch 99 training [time: 42.33s, train loss: 14841.8817]\n",
      "epoch 99 training [time: 42.33s, train loss: 14841.8817]\n",
      "epoch 99 training [time: 42.33s, train loss: 14841.8817]\n",
      "epoch 99 training [time: 42.33s, train loss: 14841.8817]\n",
      "epoch 99 training [time: 42.33s, train loss: 14841.8817]\n",
      "13 Apr 10:34    INFO  Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n",
      "Saving current: saved/GRU4Rec-Apr-13-2022_09-23-53.pth\n"
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "model = GRU4Rec(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91afeb",
   "metadata": {
    "papermill": {
     "duration": 0.386664,
     "end_time": "2022-03-20T02:50:21.838866",
     "exception": false,
     "start_time": "2022-03-20T02:50:21.452202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Create recommendation result from trained model\n",
    "\n",
    "I note document here for any one want to customize it: https://recbole.io/docs/user_guide/usage/case_study.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4736b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_user_ids = dataset.id2token(\n",
    "    dataset.uid_field, list(range(dataset.user_num)))[1:]#fist element in array is 'PAD'(default of Recbole) ->remove it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77a87d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T02:50:23.765193Z",
     "iopub.status.busy": "2022-03-20T02:50:23.764128Z",
     "iopub.status.idle": "2022-03-20T02:50:23.775557Z",
     "shell.execute_reply": "2022-03-20T02:50:23.776880Z",
     "shell.execute_reply.started": "2022-03-19T09:17:48.660391Z"
    },
    "papermill": {
     "duration": 0.703287,
     "end_time": "2022-03-20T02:50:23.777164",
     "exception": false,
     "start_time": "2022-03-20T02:50:23.073877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "def add_last_item(old_interaction, last_item_id, max_len=50):\n",
    "    new_seq_items = old_interaction['item_id_list'][-1]\n",
    "    if old_interaction['item_length'][-1].item() < max_len:\n",
    "        new_seq_items[old_interaction['item_length'][-1].item()] = last_item_id\n",
    "    else:\n",
    "        new_seq_items = torch.roll(new_seq_items, -1)\n",
    "        new_seq_items[-1] = last_item_id\n",
    "    return new_seq_items.view(1, len(new_seq_items))\n",
    "\n",
    "def predict_for_all_item(external_user_id, dataset, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        uid_series = dataset.token2id(dataset.uid_field, [external_user_id])\n",
    "        index = np.isin(dataset[dataset.uid_field].numpy(), uid_series)\n",
    "        input_interaction = dataset[index]\n",
    "        test = {\n",
    "            'item_id_list': add_last_item(input_interaction, \n",
    "                                          input_interaction['item_id'][-1].item(), model.max_seq_length),\n",
    "            'item_length': torch.tensor(\n",
    "                [input_interaction['item_length'][-1].item() + 1\n",
    "                 if input_interaction['item_length'][-1].item() < model.max_seq_length else model.max_seq_length])\n",
    "        }\n",
    "        new_inter = Interaction(test)\n",
    "        new_inter = new_inter.to(config['device'])\n",
    "        new_scores = model.full_sort_predict(new_inter)\n",
    "        new_scores = new_scores.view(-1, test_data.dataset.item_num)\n",
    "        new_scores[:, 0] = -np.inf  # set scores of [pad] to -inf\n",
    "    return torch.topk(new_scores, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2dd598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 \n",
    "# submission_index.csv 파일이 생성되기 전이라면 for_submission.py 파일을 실행해주세요.\n",
    "import pandas as pd\n",
    "user_index_ = pd.read_csv('submission_index.csv')\n",
    "\n",
    "user_index_ = np.array(user_index_['user'],dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bb8ef264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T02:50:25.539828Z",
     "iopub.status.busy": "2022-03-20T02:50:25.538457Z",
     "iopub.status.idle": "2022-03-20T03:16:02.324679Z",
     "shell.execute_reply": "2022-03-20T03:16:02.323774Z",
     "shell.execute_reply.started": "2022-03-19T09:18:22.091273Z"
    },
    "papermill": {
     "duration": 1537.179191,
     "end_time": "2022-03-20T03:16:02.324943",
     "exception": false,
     "start_time": "2022-03-20T02:50:25.145752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31356/31356 [18:30<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31356\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "topk_items = []\n",
    "for external_user_id in tqdm(external_user_ids):\n",
    "    _, topk_iid_list = predict_for_all_item(external_user_id, dataset, model)\n",
    "    last_topk_iid_list = topk_iid_list[-1]\n",
    "    external_item_list = dataset.id2token(dataset.iid_field, last_topk_iid_list.cpu()).tolist()\n",
    "    topk_items.append(external_item_list)\n",
    "print(len(topk_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "82a4826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- submission.csv -\n",
      "         user                                               item\n",
      "0          11  [48394, 5995, 48780, 3949, 5952, 55820, 30707,...\n",
      "1          14  [4025, 1947, 838, 2724, 5299, 2150, 1962, 468,...\n",
      "2          18  [64622, 65130, 63082, 60950, 63876, 71033, 723...\n",
      "3          25  [7361, 72011, 6016, 72998, 69757, 6874, 5418, ...\n",
      "4          31  [6550, 49649, 5621, 69526, 56775, 6294, 5504, ...\n",
      "...       ...                                                ...\n",
      "31351  138473  [6874, 32587, 47, 2571, 7438, 2329, 3147, 1704...\n",
      "31352  138475  [6331, 6380, 1945, 3462, 930, 7013, 1248, 7056...\n",
      "31353  138486  [6502, 7360, 40732, 4105, 6755, 1215, 53000, 5...\n",
      "31354  138492  [6296, 3552, 4002, 1663, 4499, 3210, 2109, 303...\n",
      "31355  138493  [72998, 59615, 60069, 68358, 1291, 59315, 1210...\n",
      "\n",
      "[31356 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {'user' : external_user_ids, 'item' :topk_items} \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print('- submission.csv -')\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "df.to_csv('/opt/ml/RecBole/srcs/output/submission_GRU-tmp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9983e755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['53188', '68606', '105578', '128756']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습이 되지 않은 user 추출 \n",
    "user_index = pd.read_csv('/opt/ml/RecBole/srcs/submission_index.csv')\n",
    "user_index = np.array(user_index['user'],dtype=str)\n",
    "set_unknown = set(user_index) - set(external_user_ids)\n",
    "list(set_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "92c50864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53188</td>\n",
       "      <td>3578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53188</td>\n",
       "      <td>79132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53188</td>\n",
       "      <td>2959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53188</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53188</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53188</td>\n",
       "      <td>3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53188</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53188</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53188</td>\n",
       "      <td>60069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53188</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>68606</td>\n",
       "      <td>5418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>68606</td>\n",
       "      <td>58559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>68606</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68606</td>\n",
       "      <td>48516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68606</td>\n",
       "      <td>59315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>68606</td>\n",
       "      <td>2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>68606</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>68606</td>\n",
       "      <td>50872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68606</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>68606</td>\n",
       "      <td>49530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>105578</td>\n",
       "      <td>7115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>105578</td>\n",
       "      <td>6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>105578</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>105578</td>\n",
       "      <td>3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>105578</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>105578</td>\n",
       "      <td>3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>105578</td>\n",
       "      <td>3832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>105578</td>\n",
       "      <td>6803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>105578</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>105578</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>128756</td>\n",
       "      <td>46855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>128756</td>\n",
       "      <td>6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>128756</td>\n",
       "      <td>26151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>128756</td>\n",
       "      <td>4298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>128756</td>\n",
       "      <td>25805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>128756</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>128756</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>128756</td>\n",
       "      <td>6981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>128756</td>\n",
       "      <td>8199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>128756</td>\n",
       "      <td>8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user   item\n",
       "0    53188   3578\n",
       "1    53188  79132\n",
       "2    53188   2959\n",
       "3    53188    527\n",
       "4    53188    296\n",
       "5    53188   3147\n",
       "6    53188   1240\n",
       "7    53188    480\n",
       "8    53188  60069\n",
       "9    53188    593\n",
       "10   68606   5418\n",
       "11   68606  58559\n",
       "12   68606    457\n",
       "13   68606  48516\n",
       "14   68606  59315\n",
       "15   68606   2716\n",
       "16   68606   1036\n",
       "17   68606  50872\n",
       "18   68606   6218\n",
       "19   68606  49530\n",
       "20  105578   7115\n",
       "21  105578   6140\n",
       "22  105578   1219\n",
       "23  105578   3018\n",
       "24  105578   1340\n",
       "25  105578   3970\n",
       "26  105578   3832\n",
       "27  105578   6803\n",
       "28  105578    904\n",
       "29  105578   2160\n",
       "30  128756  46855\n",
       "31  128756   6920\n",
       "32  128756  26151\n",
       "33  128756   4298\n",
       "34  128756  25805\n",
       "35  128756   7700\n",
       "36  128756     97\n",
       "37  128756   6981\n",
       "38  128756   8199\n",
       "39  128756   8125"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필터링된 user 4건에 대해 RecVAE 결과 통합 \n",
    "recvae = pd.read_csv(\"output_RecVAE.csv\")\n",
    "df_unknown = pd.DataFrame(columns=['user', 'item'])\n",
    "external_user_ids_ = external_user_ids\n",
    "# # itr = 1 \n",
    "for unknown in list(set_unknown): \n",
    "    df_tmp = recvae[recvae['user'] == int(unknown)]\n",
    "    df_unknown = pd.concat([df_unknown ,df_tmp], axis = 0, ignore_index=True) \n",
    "    \n",
    "df_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "eac49f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- submission.csv -\n",
      "      user   item\n",
      "0       11  48394\n",
      "1       11   5995\n",
      "2       11  48780\n",
      "3       11   3949\n",
      "4       11   5952\n",
      "..     ...    ...\n",
      "35  128756   7700\n",
      "36  128756     97\n",
      "37  128756   6981\n",
      "38  128756   8199\n",
      "39  128756   8125\n",
      "\n",
      "[313600 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_index = np.repeat(external_user_ids, 10)\n",
    "\n",
    "topk_items = np.array(topk_items).flatten()\n",
    "# data = {'user' : user_index, 'item' :topk_items} # external_item_list}\n",
    "data = {'user' : user_index, 'item' :topk_items} \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.sort_values(by='user')\n",
    "df = pd.concat([df, df_unknown], axis=0)\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7fd36c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "csv 파일 생성 완료\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('/opt/ml/RecBole/srcs/output/submission_GRU_.csv',index=False)\n",
    "\n",
    "print()\n",
    "print('csv 파일 생성 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fad61d",
   "metadata": {
    "papermill": {
     "duration": 0.414141,
     "end_time": "2022-03-20T03:17:00.840332",
     "exception": false,
     "start_time": "2022-03-20T03:17:00.426191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3480.556455,
   "end_time": "2022-03-20T03:17:04.204601",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-20T02:19:03.648146",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
